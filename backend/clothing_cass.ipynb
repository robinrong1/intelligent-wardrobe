{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 18:41:50.440487: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-05 18:41:50.441247: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-05 18:41:50.445667: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-05 18:41:50.460818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-05 18:41:50.478671: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-05 18:41:50.484155: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-05 18:41:50.500486: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-05 18:41:52.086249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-10-05 18:41:54.430111: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 29.45 MiB (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to /home/aditya/tensorflow_datasets/fashion_mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Projects/intelligent-wardrobe/backend/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.86 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.69 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.61 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.73 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.55 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.42 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.18 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.14 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.95 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.90 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.69 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.62 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.60 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.54 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.49 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  2.17 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:03<00:00,  2.17 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:03<00:00,  2.17 url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:03<00:00,  1.17 file/s]\n",
      "Dl Size...: 100%|██████████| 29/29 [00:03<00:00,  8.47 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:03<00:00,  1.17 url/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset fashion_mnist downloaded and prepared to /home/aditya/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "data, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
    "\n",
    "training_data, testing_data = data['train'], data['test']\n",
    "\n",
    "name_classes = metadata.features['label'].names\n",
    "\n",
    "def normalize(images, labels):\n",
    "  images = tf.cast(images, tf.float32)\n",
    "  images /= 255\n",
    "  return images, labels\n",
    "\n",
    "training_data = training_data.map(normalize)\n",
    "testing_data = testing_data.map(normalize)\n",
    "\n",
    "training_data = training_data.cache()\n",
    "testing_data = testing_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for image, label in training_data.take(1):\n",
    "   break\n",
    "image = image.numpy().reshape((28,28))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image, cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i, (image, label) in enumerate(training_data.take(25)):\n",
    "  image = image.numpy().reshape((28,28))\n",
    "  plt.subplot(5,5,i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image, cmap=plt.cm.binary)\n",
    "  plt.xlabel(name_classes[label])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Projects/intelligent-wardrobe/backend/venv/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "num_training_data = metadata.splits[\"train\"].num_examples\n",
    "num_test_data = metadata.splits[\"test\"].num_examples\n",
    "BATCH = 32\n",
    "\n",
    "training_data = training_data.repeat().shuffle(num_training_data).batch(BATCH)\n",
    "testing_data = testing_data.batch(BATCH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "res = model.fit(training_data, epochs=5, steps_per_epoch= math.ceil(num_training_data / BATCH))\n",
    "\n",
    "plt.xlabel(\"# epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(res.history[\"loss\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 50\n",
    "\n",
    "for image, label in testing_data.take(index): \n",
    "    image = image[0].numpy() \n",
    "    image = image.reshape((28, 28)) \n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.show()   \n",
    "\n",
    "    # Perform prediction\n",
    "    predictions = model.predict(image.reshape(1, 28, 28))   \n",
    "    predicted_class = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "\n",
    "    class_names = metadata.features['label'].names\n",
    "\n",
    "    # Display prediction result\n",
    "    print(f\"Predicted Class: {class_names[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
